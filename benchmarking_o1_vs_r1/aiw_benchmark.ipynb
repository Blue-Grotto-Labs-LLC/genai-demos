{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work in Progress -- Use the AIW dataset to benchmark o1-preview against r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU openai datasets tqdm pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "openai_api_key = getpass.getpass(\"OpenAI API key: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Angela/Desktop/genai-demos/benchmarking_o1_vs_r1/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating train split: 100%|██████████| 274/274 [00:00<00:00, 37538.44 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the \"Alice in Wonderland\" dataset from Hugging Face\n",
    "dataset = load_dataset(\"marianna13/aiw-prompts\")\n",
    "data = dataset['test'] if 'test' in dataset else dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': [1, 2, 3, 4, 5], 'text': [\"Alice has 4 brothers and she also has 1 sister. How many sisters does Alice's brother have? To answer the question, DO NOT OUTPUT ANY TEXT EXCEPT following format that contains final answer: ### Answer:\", \"Alice has 4 sisters and she also has 1 brother. How many sisters does Alice's brother have? To answer the question, DO NOT OUTPUT ANY TEXT EXCEPT following format that contains final answer: ### Answer:\", \"Alice has four brothers and she also has one sister. How many sisters does Alice's brother have? To answer the question, DO NOT OUTPUT ANY TEXT EXCEPT following format that contains final answer: ### Answer:\", \"Alice has four sisters and she also has one brother. How many sisters does Alice's brother have? To answer the question, DO NOT OUTPUT ANY TEXT EXCEPT following format that contains final answer: ### Answer:\", \"Alice has 4 brothers and she also has 1 sister. How many sisters does Alice's brother have?\"], 'right_answer': ['2', '5', '2', '5', '2'], 'description': ['original prompt', 'easy prompt', 'original prompt, words instead numbers', 'easy prompt, words instead numbers', 'original prompt, plain, no format enforcement']}\n"
     ]
    }
   ],
   "source": [
    "print(data[:5])  # Inspect the first 5 rows of 'data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Function to query the OpenAI model\n",
    "client = openai.OpenAI(api_key=openai_api_key)\n",
    "\n",
    "async def query_openai(prompt, model=\"o1-preview-2024-09-12\"):\n",
    "    try:\n",
    "        response = await client.chat.completions.acreate(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "        )\n",
    "        return response.choices[0].message.content.strip(), response.usage\n",
    "    except Exception as e:\n",
    "        return str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m answer, usage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m query_openai(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhat is the capital of England\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(answer)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(usage)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "answer, usage = await query_openai(\"what is the capital of England\")\n",
    "print(answer)\n",
    "print(usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of England is London.\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Validate OpenAI's model against the dataset\n",
    "results = []\n",
    "\n",
    "for item in tqdm(data):\n",
    "    prompt = item[\"prompt\"]\n",
    "    expected = item[\"completion\"]  # Adjust the key if necessary\n",
    "\n",
    "    # Query the OpenAI model\n",
    "    generated_answer, usage = await query_openai(prompt)\n",
    "\n",
    "    # Record the results\n",
    "    results.append({\n",
    "        \"prompt\": prompt,\n",
    "        \"expected\": expected,\n",
    "        \"generated\": generated\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Convert results to a DataFrame for analysis\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Calculate the percentage of correct responses\n",
    "results_df[\"is_correct\"] = results_df[\"expected\"] == results_df[\"generated\"]\n",
    "accuracy = results_df[\"is_correct\"].mean() * 100\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\"validation_results.csv\", index=False)\n",
    "\n",
    "# Display a preview of the results and accuracy\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "results_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
